{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of model_autoencoder.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KJhQQfXszhE"
      },
      "source": [
        "#code by Duc Huy Nguyen\n",
        "#ref: \n",
        "# https://github.com/y-kawagu/dcase2020_task2_baseline/tree/ebfcc2ae886511d074a4e746890c3ef877800de0\n",
        "# https://github.com/AlexandrineRibeiro/DCASE-2020-Task-2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ElbyutAtfEk",
        "outputId": "c09ca7a9-0649-484b-8f5f-e7a479084c77"
      },
      "source": [
        "!pip install pqdm\n",
        "import csv\n",
        "import glob\n",
        "import multiprocessing\n",
        "import os\n",
        "\n",
        "import sys\n",
        "from functools import partial\n",
        "from venv import logger\n",
        "import re\n",
        "import itertools\n",
        "\n",
        "import librosa\n",
        "import librosa.core\n",
        "import librosa.feature\n",
        "\n",
        "import numpy\n",
        "import pandas as pd\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
        "import keras.models\n",
        "from keras.layers import Input, Dense, BatchNormalization\n",
        "from keras.models import Model\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "import tqdm\n",
        "from pqdm.processes import pqdm\n",
        "import matplotlib.pyplot as plt  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pqdm in /usr/local/lib/python3.7/dist-packages (0.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pqdm) (4.41.1)\n",
            "Requirement already satisfied: bounded-pool-executor in /usr/local/lib/python3.7/dist-packages (from pqdm) (0.0.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from pqdm) (3.7.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvV9wqFzJyFW"
      },
      "source": [
        "\n",
        "def file_load(wav_name, mono=False):\n",
        "    \"\"\"\n",
        "    load .wav file.\n",
        "    wav_name : str\n",
        "        target .wav file\n",
        "    sampling_rate : int\n",
        "        audio file sampling_rate\n",
        "    mono : boolean\n",
        "        When load a multi channels file and this param True, the returned data will be merged for mono data\n",
        "    return : numpy.array( float )\n",
        "    \"\"\"\n",
        "    try:\n",
        "        return librosa.load(wav_name, sr=None, mono=mono)\n",
        "    except:\n",
        "        logger.error(\"file_broken or not exists!! : {}\".format(wav_name))\n",
        "# feature extractor\n",
        "def raw_feature_extractor(audio_path):\n",
        "  data=file_load(audio_path)\n",
        "  frequency = data[1]\n",
        "  totalLength=len(data[0])\n",
        "  sounddata=data[0]*1000\n",
        "  newvector = []\n",
        "  for i in range(int(totalLength/160)):\n",
        "      frame = numpy.asarray(sounddata[160*i:160*(i+1)])\n",
        "      #frame = numpy.asarray(frame)\n",
        "      newvector.append(frame)\n",
        "\n",
        "  return numpy.asarray(newvector)\n",
        "  \n",
        "def file_to_array(train_files):\n",
        "    #par_file = partial(MFEC_extractor)\n",
        "    par_file = partial(Raw_feature_extractor)\n",
        "    files = pqdm(train_files, par_file, n_jobs=multiprocessing.cpu_count())\n",
        "    files_list = []\n",
        "    for i in files:\n",
        "        files_list.append(i)\n",
        "    array = numpy.asarray(files_list)\n",
        "    array = array.reshape(array.shape[1] * len(files), array.shape[2])\n",
        "    return array\n",
        "\n",
        "\n",
        "def get_model(inputDim, name_for_model=\"\"):\n",
        "    \"\"\"\n",
        "    define the keras model\n",
        "    the model based on the simple dense auto encoder\n",
        "    (128*128*128*8*128*128*128)\n",
        "    \"\"\"\n",
        "    inputLayer = Input(shape=(inputDim,))\n",
        "\n",
        "    h = Dense(128)(inputLayer)  \n",
        "    h = BatchNormalization()(h)\n",
        "    h = keras.layers.ReLU()(h)\n",
        "\n",
        "    #h = Dense(512)(h)\n",
        "    #h = BatchNormalization()(h)\n",
        "    #h = keras.layers.ReLU()(h)\n",
        "\n",
        "    h = Dense(128)(h)\n",
        "    h = BatchNormalization()(h)\n",
        "    h = keras.layers.ReLU()(h)\n",
        "\n",
        "    h = Dense(128)(h)\n",
        "    h = BatchNormalization()(h)\n",
        "    h = keras.layers.ReLU()(h)\n",
        "\n",
        "    h = Dense(8)(h)\n",
        "    h = BatchNormalization()(h)\n",
        "    h = keras.layers.ReLU()(h)\n",
        "\n",
        "    #h = Dense(512)(h)\n",
        "    #h = BatchNormalization()(h)\n",
        "    #h = keras.layers.ReLU()(h)\n",
        "\n",
        "    h = Dense(128)(h)\n",
        "    h = BatchNormalization()(h)\n",
        "    h = keras.layers.ReLU()(h)\n",
        "\n",
        "    h = Dense(128)(h)\n",
        "    h = BatchNormalization()(h)\n",
        "    h = keras.layers.ReLU()(h)\n",
        "\n",
        "    h = Dense(128)(h)\n",
        "    h = BatchNormalization()(h)\n",
        "    h = keras.layers.ReLU()(h)\n",
        "\n",
        "    h = Dense(inputDim)(h)\n",
        "\n",
        "    AutoEncoder = Model(inputLayer, h, name='AE' + name_for_model)\n",
        "    AutoEncoder.compile(optimizer='adam', loss=\"mse\")\n",
        "    return AutoEncoder\n",
        "def eval_model_stream(target_dir, model, machine_type):\n",
        "    from tqdm import tqdm\n",
        "    test_dir = target_dir+'/test'\n",
        "    files = os.listdir(test_dir)[0]\n",
        "\n",
        "    id = re.findall('id_[0-9][0-9]',files) \n",
        "\n",
        "    test_files, y_true = test_file_list_generator(target_dir, id)\n",
        "\n",
        "    print(\"\\n============== BEGIN TEST ==================\")\n",
        "    MSE_score = [0. for k in test_files]\n",
        "    for id, file_path in tqdm(enumerate(test_files), total=len(test_files)):\n",
        "        #data = file_to_vector_array_stream_test_data(file_path)\n",
        "        data = raw_feature_extractor(file_path)\n",
        "        reconstruction_loss = (data - model.predict(data))\n",
        "        errors_arr = numpy.mean(numpy.square(reconstruction_loss), axis=1)\n",
        "        MSE_score[id] = numpy.mean(errors_arr)\n",
        "        \n",
        "\n",
        "        #Draw AUC/pAUC table\n",
        "    fpr, tpr, threshold = roc_curve(y_true, MSE_score)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    plt.plot(fpr, tpr, label='AUC = ' + str(round(roc_auc, 2)))\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "    #Extract fpr and threshold\n",
        "    Auc = roc_auc_score(y_true, MSE_score)\n",
        "    p_auc = roc_auc_score(y_true, MSE_score, max_fpr=0.1)\n",
        "    print(\"AUC : {}\".format(Auc))\n",
        "    print(\"pAUC : {}\".format(p_auc))\n",
        "\n",
        "    print(\"\\n============ END TEST ============\")\n",
        "\n",
        "    return  fpr, tpr, threshold\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def test_file_list_generator(target_dir, id_name, dir_name=\"test\",\n",
        "                             prefix_normal=\"normal\", prefix_anomaly=\"anomaly\",\n",
        "                             ext=\"wav\"):\n",
        "    normal_files = sorted(\n",
        "        glob.glob(\"{dir}/{dir_name}/{prefix_normal}_{id_name}*.{ext}\"\n",
        "                  .format(dir=target_dir, dir_name=dir_name,\n",
        "                          prefix_normal=prefix_normal,\n",
        "                          id_name=id_name, ext=ext)))\n",
        "\n",
        "    normal_labels = numpy.zeros(len(normal_files))\n",
        "    anomaly_files = sorted(\n",
        "        glob.glob(\"{dir}/{dir_name}/{prefix_anomaly}_{id_name}*.{ext}\"\n",
        "                  .format(dir=target_dir, dir_name=dir_name,\n",
        "                          prefix_anomaly=prefix_anomaly,\n",
        "                          id_name=id_name, ext=ext)))\n",
        "\n",
        "    anomaly_labels = numpy.ones(len(anomaly_files))\n",
        "    files = numpy.concatenate((normal_files, anomaly_files), axis=0)\n",
        "    labels = numpy.concatenate((normal_labels, anomaly_labels), axis=0)\n",
        "\n",
        "    if len(files) == 0:\n",
        "        print(\"no_wav_file!!\")\n",
        "\n",
        "    return files, labels\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9foUItWH-dl",
        "outputId": "77a3c676-e13d-4cbd-d483-dc4f394bb090"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    path = \"/content/drive/MyDrive/luanvan/dulieu/\"\n",
        "    os.chdir(path)\n",
        "    folders = [\"fan\"]\n",
        "    #folders = [\"fan0\",\"fan2\"]\n",
        "    \n",
        "\n",
        "    for f in folders:\n",
        "        callbacks_listv1 = [\n",
        "            keras.callbacks.EarlyStopping(\n",
        "                monitor='val_loss',\n",
        "                mode='min',\n",
        "                patience=5,\n",
        "                min_delta=0.01,\n",
        "                restore_best_weights=True,\n",
        "\n",
        "            ), keras.callbacks.ModelCheckpoint(\n",
        "                monitor='val_loss',\n",
        "                mode='min',\n",
        "                filepath=path+ f + \"/bestModel\" + \"_\" + f + \".H5\",\n",
        "                save_best_only=True,\n",
        "                verbose=1\n",
        "            )]\n",
        "        files_Read = []\n",
        "        print(\"Processing\", f)\n",
        "\n",
        "        for file in glob.glob(f+\"/train/*.wav\"):\n",
        "            files_Read.append(file)\n",
        "        input = file_to_array(files_Read)  \n",
        "        AutoEncoder = get_model(inputDim=input.shape[1], name_for_model=f)\n",
        "        AutoEncoder.fit(input, input, batch_size=256, epochs=50, callbacks=callbacks_listv1, validation_split=0.3)\n",
        "        AEBest = keras.models.load_model(path+f+\"/bestModel\" + \"_\" + f + \".H5\")\n",
        "        fpr, tpr, threshold = eval_model_stream(path+ f , AEBest, f)\n",
        "        print(\"fpr: \", fpr)\n",
        "        print(\"threshold: \", threshold)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rSUBMITTING | :   0%|          | 0/334 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing fan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "SUBMITTING | : 100%|██████████| 334/334 [00:00<00:00, 2551.43it/s]\n",
            "PROCESSING | : 100%|██████████| 334/334 [00:01<00:00, 169.95it/s]\n",
            "COLLECTING | : 100%|██████████| 334/334 [00:00<00:00, 94937.49it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "914/914 [==============================] - 15s 13ms/step - loss: 46.7262 - val_loss: 61.3324\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 61.33236, saving model to /content/drive/MyDrive/luanvan/dulieu/fan/bestModel_fan.H5\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/luanvan/dulieu/fan/bestModel_fan.H5/assets\n",
            "Epoch 2/50\n",
            "914/914 [==============================] - 12s 13ms/step - loss: 36.0552 - val_loss: 60.2150\n",
            "\n",
            "Epoch 00002: val_loss improved from 61.33236 to 60.21500, saving model to /content/drive/MyDrive/luanvan/dulieu/fan/bestModel_fan.H5\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/luanvan/dulieu/fan/bestModel_fan.H5/assets\n",
            "Epoch 3/50\n",
            "914/914 [==============================] - 12s 13ms/step - loss: 35.2054 - val_loss: 55.6515\n",
            "\n",
            "Epoch 00003: val_loss improved from 60.21500 to 55.65149, saving model to /content/drive/MyDrive/luanvan/dulieu/fan/bestModel_fan.H5\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/luanvan/dulieu/fan/bestModel_fan.H5/assets\n",
            "Epoch 4/50\n",
            "914/914 [==============================] - 12s 13ms/step - loss: 33.5651 - val_loss: 55.4602\n",
            "\n",
            "Epoch 00004: val_loss improved from 55.65149 to 55.46019, saving model to /content/drive/MyDrive/luanvan/dulieu/fan/bestModel_fan.H5\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/luanvan/dulieu/fan/bestModel_fan.H5/assets\n",
            "Epoch 5/50\n",
            "914/914 [==============================] - 12s 13ms/step - loss: 32.2757 - val_loss: 51.4776\n",
            "\n",
            "Epoch 00005: val_loss improved from 55.46019 to 51.47763, saving model to /content/drive/MyDrive/luanvan/dulieu/fan/bestModel_fan.H5\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/luanvan/dulieu/fan/bestModel_fan.H5/assets\n",
            "Epoch 6/50\n",
            "914/914 [==============================] - 12s 13ms/step - loss: 31.4772 - val_loss: 51.0967\n",
            "\n",
            "Epoch 00006: val_loss improved from 51.47763 to 51.09671, saving model to /content/drive/MyDrive/luanvan/dulieu/fan/bestModel_fan.H5\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/luanvan/dulieu/fan/bestModel_fan.H5/assets\n",
            "Epoch 7/50\n",
            "914/914 [==============================] - 12s 13ms/step - loss: 31.4207 - val_loss: 50.7443\n",
            "\n",
            "Epoch 00007: val_loss improved from 51.09671 to 50.74430, saving model to /content/drive/MyDrive/luanvan/dulieu/fan/bestModel_fan.H5\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/luanvan/dulieu/fan/bestModel_fan.H5/assets\n",
            "Epoch 8/50\n",
            "914/914 [==============================] - 12s 13ms/step - loss: 31.3304 - val_loss: 50.2238\n",
            "\n",
            "Epoch 00008: val_loss improved from 50.74430 to 50.22383, saving model to /content/drive/MyDrive/luanvan/dulieu/fan/bestModel_fan.H5\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/luanvan/dulieu/fan/bestModel_fan.H5/assets\n",
            "Epoch 9/50\n",
            "914/914 [==============================] - 12s 13ms/step - loss: 30.9796 - val_loss: 49.7566\n",
            "\n",
            "Epoch 00009: val_loss improved from 50.22383 to 49.75663, saving model to /content/drive/MyDrive/luanvan/dulieu/fan/bestModel_fan.H5\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/luanvan/dulieu/fan/bestModel_fan.H5/assets\n",
            "Epoch 10/50\n",
            "914/914 [==============================] - 12s 13ms/step - loss: 30.6987 - val_loss: 49.3670\n",
            "\n",
            "Epoch 00010: val_loss improved from 49.75663 to 49.36699, saving model to /content/drive/MyDrive/luanvan/dulieu/fan/bestModel_fan.H5\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/luanvan/dulieu/fan/bestModel_fan.H5/assets\n",
            "Epoch 11/50\n",
            "914/914 [==============================] - 12s 13ms/step - loss: 30.5728 - val_loss: 48.6968\n",
            "\n",
            "Epoch 00011: val_loss improved from 49.36699 to 48.69681, saving model to /content/drive/MyDrive/luanvan/dulieu/fan/bestModel_fan.H5\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/luanvan/dulieu/fan/bestModel_fan.H5/assets\n",
            "Epoch 12/50\n",
            "914/914 [==============================] - 12s 13ms/step - loss: 30.3070 - val_loss: 48.6609\n",
            "\n",
            "Epoch 00012: val_loss improved from 48.69681 to 48.66088, saving model to /content/drive/MyDrive/luanvan/dulieu/fan/bestModel_fan.H5\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/luanvan/dulieu/fan/bestModel_fan.H5/assets\n",
            "Epoch 13/50\n",
            "914/914 [==============================] - 12s 13ms/step - loss: 30.3211 - val_loss: 48.5474\n",
            "\n",
            "Epoch 00013: val_loss improved from 48.66088 to 48.54738, saving model to /content/drive/MyDrive/luanvan/dulieu/fan/bestModel_fan.H5\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/luanvan/dulieu/fan/bestModel_fan.H5/assets\n",
            "Epoch 14/50\n",
            "914/914 [==============================] - 12s 13ms/step - loss: 30.1324 - val_loss: 48.1168\n",
            "\n",
            "Epoch 00014: val_loss improved from 48.54738 to 48.11684, saving model to /content/drive/MyDrive/luanvan/dulieu/fan/bestModel_fan.H5\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/luanvan/dulieu/fan/bestModel_fan.H5/assets\n",
            "Epoch 15/50\n",
            "914/914 [==============================] - 12s 13ms/step - loss: 30.0636 - val_loss: 48.6765\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 48.11684\n",
            "Epoch 16/50\n",
            "914/914 [==============================] - 12s 13ms/step - loss: 30.0147 - val_loss: 48.3663\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 48.11684\n",
            "Epoch 17/50\n",
            "914/914 [==============================] - 12s 13ms/step - loss: 29.9260 - val_loss: 48.0724\n",
            "\n",
            "Epoch 00017: val_loss improved from 48.11684 to 48.07235, saving model to /content/drive/MyDrive/luanvan/dulieu/fan/bestModel_fan.H5\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/luanvan/dulieu/fan/bestModel_fan.H5/assets\n",
            "Epoch 18/50\n",
            "914/914 [==============================] - 12s 13ms/step - loss: 29.8386 - val_loss: 47.8851\n",
            "\n",
            "Epoch 00018: val_loss improved from 48.07235 to 47.88508, saving model to /content/drive/MyDrive/luanvan/dulieu/fan/bestModel_fan.H5\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/luanvan/dulieu/fan/bestModel_fan.H5/assets\n",
            "Epoch 19/50\n",
            "914/914 [==============================] - 12s 13ms/step - loss: 29.8759 - val_loss: 47.4307\n",
            "\n",
            "Epoch 00019: val_loss improved from 47.88508 to 47.43073, saving model to /content/drive/MyDrive/luanvan/dulieu/fan/bestModel_fan.H5\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/luanvan/dulieu/fan/bestModel_fan.H5/assets\n",
            "Epoch 20/50\n",
            "914/914 [==============================] - 12s 13ms/step - loss: 29.7034 - val_loss: 47.8483\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 47.43073\n",
            "Epoch 21/50\n",
            "914/914 [==============================] - 12s 13ms/step - loss: 29.7592 - val_loss: 47.3243\n",
            "\n",
            "Epoch 00021: val_loss improved from 47.43073 to 47.32429, saving model to /content/drive/MyDrive/luanvan/dulieu/fan/bestModel_fan.H5\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/luanvan/dulieu/fan/bestModel_fan.H5/assets\n",
            "Epoch 22/50\n",
            "914/914 [==============================] - 12s 13ms/step - loss: 29.6729 - val_loss: 47.3543\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 47.32429\n",
            "Epoch 23/50\n",
            "914/914 [==============================] - 12s 13ms/step - loss: 29.6481 - val_loss: 47.2005\n",
            "\n",
            "Epoch 00023: val_loss improved from 47.32429 to 47.20046, saving model to /content/drive/MyDrive/luanvan/dulieu/fan/bestModel_fan.H5\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/luanvan/dulieu/fan/bestModel_fan.H5/assets\n",
            "Epoch 24/50\n",
            "914/914 [==============================] - 12s 13ms/step - loss: 29.5651 - val_loss: 47.5324\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 47.20046\n",
            "Epoch 25/50\n",
            "914/914 [==============================] - 12s 13ms/step - loss: 29.5391 - val_loss: 47.0267\n",
            "\n",
            "Epoch 00025: val_loss improved from 47.20046 to 47.02674, saving model to /content/drive/MyDrive/luanvan/dulieu/fan/bestModel_fan.H5\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/luanvan/dulieu/fan/bestModel_fan.H5/assets\n",
            "Epoch 26/50\n",
            "914/914 [==============================] - 12s 13ms/step - loss: 29.5109 - val_loss: 47.1709\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 47.02674\n",
            "Epoch 27/50\n",
            "914/914 [==============================] - 12s 13ms/step - loss: 29.4926 - val_loss: 47.1083\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 47.02674\n",
            "Epoch 28/50\n",
            "914/914 [==============================] - 12s 13ms/step - loss: 29.3650 - val_loss: 47.4972\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 47.02674\n",
            "Epoch 29/50\n",
            "914/914 [==============================] - 12s 13ms/step - loss: 29.4173 - val_loss: 48.3603\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 47.02674\n",
            "Epoch 30/50\n",
            "914/914 [==============================] - 12s 13ms/step - loss: 29.3568 - val_loss: 46.7174\n",
            "\n",
            "Epoch 00030: val_loss improved from 47.02674 to 46.71740, saving model to /content/drive/MyDrive/luanvan/dulieu/fan/bestModel_fan.H5\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/luanvan/dulieu/fan/bestModel_fan.H5/assets\n",
            "Epoch 31/50\n",
            "914/914 [==============================] - 12s 13ms/step - loss: 29.3285 - val_loss: 46.6059\n",
            "\n",
            "Epoch 00031: val_loss improved from 46.71740 to 46.60590, saving model to /content/drive/MyDrive/luanvan/dulieu/fan/bestModel_fan.H5\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/luanvan/dulieu/fan/bestModel_fan.H5/assets\n",
            "Epoch 32/50\n",
            "914/914 [==============================] - 12s 13ms/step - loss: 29.2557 - val_loss: 46.7921\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 46.60590\n",
            "Epoch 33/50\n",
            "914/914 [==============================] - 12s 13ms/step - loss: 29.2331 - val_loss: 47.2036\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 46.60590\n",
            "Epoch 34/50\n",
            "914/914 [==============================] - 12s 13ms/step - loss: 29.2116 - val_loss: 46.4076\n",
            "\n",
            "Epoch 00034: val_loss improved from 46.60590 to 46.40760, saving model to /content/drive/MyDrive/luanvan/dulieu/fan/bestModel_fan.H5\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/luanvan/dulieu/fan/bestModel_fan.H5/assets\n",
            "Epoch 35/50\n",
            "914/914 [==============================] - 12s 13ms/step - loss: 29.2020 - val_loss: 46.5197\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 46.40760\n",
            "Epoch 36/50\n",
            "914/914 [==============================] - 12s 13ms/step - loss: 29.1112 - val_loss: 46.6624\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 46.40760\n",
            "Epoch 37/50\n",
            "914/914 [==============================] - 12s 13ms/step - loss: 29.1067 - val_loss: 46.4952\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 46.40760\n",
            "Epoch 38/50\n",
            "914/914 [==============================] - 12s 13ms/step - loss: 28.9854 - val_loss: 46.5532\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 46.40760\n",
            "Epoch 39/50\n",
            "914/914 [==============================] - 12s 13ms/step - loss: 29.0362 - val_loss: 46.0749\n",
            "\n",
            "Epoch 00039: val_loss improved from 46.40760 to 46.07492, saving model to /content/drive/MyDrive/luanvan/dulieu/fan/bestModel_fan.H5\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/luanvan/dulieu/fan/bestModel_fan.H5/assets\n",
            "Epoch 40/50\n",
            "914/914 [==============================] - 12s 13ms/step - loss: 28.9687 - val_loss: 47.1140\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 46.07492\n",
            "Epoch 41/50\n",
            "914/914 [==============================] - 12s 13ms/step - loss: 28.9264 - val_loss: 46.0111\n",
            "\n",
            "Epoch 00041: val_loss improved from 46.07492 to 46.01111, saving model to /content/drive/MyDrive/luanvan/dulieu/fan/bestModel_fan.H5\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/luanvan/dulieu/fan/bestModel_fan.H5/assets\n",
            "Epoch 42/50\n",
            "914/914 [==============================] - 12s 13ms/step - loss: 28.9087 - val_loss: 47.5537\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 46.01111\n",
            "Epoch 43/50\n",
            "914/914 [==============================] - 12s 13ms/step - loss: 28.8206 - val_loss: 47.7000\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 46.01111\n",
            "Epoch 44/50\n",
            "914/914 [==============================] - 12s 13ms/step - loss: 28.8108 - val_loss: 46.1270\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 46.01111\n",
            "Epoch 45/50\n",
            "914/914 [==============================] - 12s 13ms/step - loss: 28.8343 - val_loss: 45.9714\n",
            "\n",
            "Epoch 00045: val_loss improved from 46.01111 to 45.97143, saving model to /content/drive/MyDrive/luanvan/dulieu/fan/bestModel_fan.H5\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/luanvan/dulieu/fan/bestModel_fan.H5/assets\n",
            "Epoch 46/50\n",
            "914/914 [==============================] - 12s 13ms/step - loss: 28.6851 - val_loss: 46.0277\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 45.97143\n",
            "Epoch 47/50\n",
            "914/914 [==============================] - 12s 13ms/step - loss: 28.7295 - val_loss: 47.8056\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 45.97143\n",
            "Epoch 48/50\n",
            "914/914 [==============================] - 12s 13ms/step - loss: 28.8350 - val_loss: 45.8612\n",
            "\n",
            "Epoch 00048: val_loss improved from 45.97143 to 45.86116, saving model to /content/drive/MyDrive/luanvan/dulieu/fan/bestModel_fan.H5\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/luanvan/dulieu/fan/bestModel_fan.H5/assets\n",
            "Epoch 49/50\n",
            "914/914 [==============================] - 12s 13ms/step - loss: 28.8409 - val_loss: 45.9992\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 45.86116\n",
            "Epoch 50/50\n",
            "914/914 [==============================] - 12s 13ms/step - loss: 28.7591 - val_loss: 46.2734\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 45.86116\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/129 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "============== BEGIN TEST FOR ID ==============\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 129/129 [00:13<00:00,  9.46it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "AUC : 0.990625\n",
            "pAUC : 0.9919028340080972\n",
            "\n",
            "============ END OF TEST FOR A MACHINE ID ============\n",
            "fpr:  [0.       0.       0.       0.015625 0.078125 0.15625  0.25     0.265625\n",
            " 0.484375 0.515625 0.609375 0.609375 1.      ]\n",
            "threshold:  [3986.2415   3985.2415     61.31106    58.676804   57.81195    56.429047\n",
            "   56.300148   56.13894    55.439667   55.2579     53.8557     45.715477\n",
            "   12.925196]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "foFT7gy1skg4",
        "outputId": "e16cdae6-06cc-4d2f-845b-3f0577f0fe2e"
      },
      "source": [
        "fpr_accept = 0.1\n",
        "for i in range(len(fpr)):\n",
        "  if fpr[i]> fpr_accept:\n",
        "    _ = i-1\n",
        "    break\n",
        "print(\"with fp rate = \",fpr_accept ,\"threshold =\", threshold[_])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "with fp rate =  0.1 threshold = 93.551315\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o04ORICOqZ53",
        "outputId": "3e7b3af0-35e2-4e5c-e83e-634ff097310d"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Convert the model\n",
        "#converter = tf.lite.TFLiteConverter.from_saved_model(\"/content/drive/MyDrive/luanvan/data/bestModel_fan.H5\") # path to the SavedModel directory\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(AEBest)\n",
        "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
        "tflite_model = converter.convert()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpja7deqjs/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLegzOdtrX2R",
        "outputId": "dfc1c7b4-cb21-48ab-9e95-b1e585d806f1"
      },
      "source": [
        "path = os.getcwd()\n",
        "path\n",
        "os.chdir(\"/content/drive/MyDrive/luanvan/dulieu/tflite\")\n",
        "# Save the model.\n",
        "open('model.tflite', 'wb').write(tflite_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "116992"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aqcj_fyix_IJ",
        "outputId": "cbf76e03-71e2-45b6-e358-2f1e2dd09624"
      },
      "source": [
        "AEBest = keras.models.load_model(\"/content/drive/MyDrive/luanvan/dulieu/fan\"+\"/bestModel\" + \"_\" + f + \".H5\")\n",
        "AEBest.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"AEfan\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 160)]             0         \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 128)               20608     \n",
            "_________________________________________________________________\n",
            "batch_normalization_18 (Batc (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "re_lu_18 (ReLU)              (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "batch_normalization_19 (Batc (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "re_lu_19 (ReLU)              (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "batch_normalization_20 (Batc (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "re_lu_20 (ReLU)              (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 8)                 1032      \n",
            "_________________________________________________________________\n",
            "batch_normalization_21 (Batc (None, 8)                 32        \n",
            "_________________________________________________________________\n",
            "re_lu_21 (ReLU)              (None, 8)                 0         \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 128)               1152      \n",
            "_________________________________________________________________\n",
            "batch_normalization_22 (Batc (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "re_lu_22 (ReLU)              (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "batch_normalization_23 (Batc (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "re_lu_23 (ReLU)              (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "batch_normalization_24 (Batc (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "re_lu_24 (ReLU)              (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 160)               20640     \n",
            "=================================================================\n",
            "Total params: 112,584\n",
            "Trainable params: 111,032\n",
            "Non-trainable params: 1,552\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}